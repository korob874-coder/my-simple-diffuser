A lightweight and educational implementation of diffusion models for generative AI, built with PyTorch.

## ğŸš€ Features

- **Simple Diffusion Implementation**: Clean and understandable codebase for learning diffusion models
- **Training Pipeline**: Complete training workflow with customizable parameters
- **Generation Module**: Generate new samples from trained diffusion models
- **Dataset Support**: Compatible with various image datasets (including cat/dog 64x64 pixel dataset)
- **Modular Design**: Separated components for model, dataset, training, and generation

## ğŸ“ Project Structure

```

my-simple-diffuser/
â”œâ”€â”€model.py          # Diffusion model architecture
â”œâ”€â”€train.py          # Training script and loop
â”œâ”€â”€generate.py       # Sample generation utilities
â”œâ”€â”€dataset.py        # Data loading and preprocessing
â”œâ”€â”€data/             # Dataset directory
â”œâ”€â”€requirements.txt  # Project dependencies
â””â”€â”€README.md         # Project documentation

```

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/korob874-coder/my-simple-diffuser.git
cd my-simple-diffuser
```

1. Install dependencies:

```bash
pip install -r requirements.txt
```

ğŸƒâ€â™‚ï¸ Quick Start

Training

```bash
python train.py --dataset path/to/your/dataset --epochs 100
```

Generation

```bash
python generate.py --checkpoint path/to/checkpoint.pth --samples 10
```

ğŸ“Š Results

The model learns to generate coherent images through the diffusion process:

Â· Forward Process: Gradually add noise to data
Â· Reverse Process: Learn to denoise and generate new samples

ğŸ¯ Use Cases

Â· Educational purposes for understanding diffusion models
Â· Research experiments with different architectures
Â· Starting point for more complex generative AI projects

ğŸ¤ Contributing

Feel free to fork this project and submit pull requests for any improvements!

ğŸ“ License

This project is open source and available under the MIT License.



Built with â¤ï¸ using PyTorch and Google Colab
